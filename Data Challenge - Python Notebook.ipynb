{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEXSH30pJItR"
   },
   "source": [
    "**Name**: Anirudh Rao\n",
    "\n",
    "**Roll No.**: BE21B004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViA_sDuLJJlW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xqG2Op7VkIf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLlwFt7pm2c8"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6ItyXpYvuxK"
   },
   "outputs": [],
   "source": [
    "embeddings1 = np.load('/content/drive/MyDrive/da5401-2024-ml-challenge/embeddings_1.npy')\n",
    "embeddings2 = np.load('/content/drive/MyDrive/da5401-2024-ml-challenge/embeddings_2.npy')\n",
    "embeddings = np.concatenate([embeddings1, embeddings2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2t7mHKu5vxE7"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/da5401-2024-ml-challenge/icd_codes_1.txt', 'rt') as f:\n",
    "    codes1 = [line.strip('\\n').split(';') for line in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "with open('/content/drive/MyDrive/da5401-2024-ml-challenge/icd_codes_2.txt', 'rt') as f:\n",
    "    codes2 = [line.strip('\\n').split(';') for line in f.readlines()]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jT0L2nrT04b"
   },
   "outputs": [],
   "source": [
    "codes = codes1 + codes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEcZ0jMpkbJ3"
   },
   "outputs": [],
   "source": [
    "all_codes = set()\n",
    "\n",
    "for code_list in codes:\n",
    "    for code in code_list:\n",
    "        all_codes.add(code)\n",
    "\n",
    "all_codes = list(all_codes)\n",
    "all_codes.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q7QKBA4iBXl"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58LfLCHzkGfN"
   },
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czTMLttUkVpQ"
   },
   "outputs": [],
   "source": [
    "len(all_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld1KgVT0m95q"
   },
   "outputs": [],
   "source": [
    "alpha_codes = [[x[0] for x in codelist] for codelist in codes]\n",
    "\n",
    "all_alpha = set()\n",
    "for code_list in alpha_codes:\n",
    "    for code in code_list:\n",
    "        all_alpha.add(code)\n",
    "\n",
    "all_alpha = list(all_alpha)\n",
    "all_alpha.sort()\n",
    "\n",
    "len(all_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKURJletZgrY"
   },
   "outputs": [],
   "source": [
    "print(\"-\".join(all_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbVSLcBUZlf4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "alpha_codes_binarized = mlb.fit_transform(alpha_codes)\n",
    "alpha_counts = pd.DataFrame(dict(zip(all_alpha, np.sum(alpha_codes_binarized, axis=0))), index=[0]).T.sort_values(by=0, ascending=False)\n",
    "alpha_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaXiSeCEaDFN"
   },
   "outputs": [],
   "source": [
    "encoded_codes = mlb.fit_transform(codes)\n",
    "counts = pd.DataFrame(dict(zip(all_codes, np.sum(encoded_codes, axis=0))), index=[0]).T.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jnEh1CcaVRU"
   },
   "outputs": [],
   "source": [
    "counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUn9d2_vaW2K"
   },
   "outputs": [],
   "source": [
    "counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UncdAFDkaYPp"
   },
   "outputs": [],
   "source": [
    "counts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m657GLwpafS5"
   },
   "outputs": [],
   "source": [
    "len(counts[counts[0] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0uS8XxdalX1"
   },
   "outputs": [],
   "source": [
    "len(counts[counts[0] <= 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVDTFaOpaq4c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.histplot(counts[0], kde=True)\n",
    "plt.xlabel(\"Number of occurrences of ICD code\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vemrPQvZa66Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(embeddings)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vON2FwkWbHGZ"
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHrlkIUbbIwW"
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], alpha = 0.25)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9-ZPqeSbKah"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8,3,dpi=150,figsize=(15,20))\n",
    "\n",
    "for i in range(len(all_alpha)):\n",
    "\n",
    "    alphabet = all_alpha[i]\n",
    "\n",
    "    ax[i//3, i%3].scatter(pca_data[:,0], pca_data[:,1], alpha = 0.25, c = alpha_codes_binarized[:,i])\n",
    "    ax[i//3, i%3].set_title(alphabet)\n",
    "    ax[i//3, i%3].set_xlabel('PC1')\n",
    "    ax[i//3, i%3].set_ylabel('PC2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu7r0OM5bNPT"
   },
   "outputs": [],
   "source": [
    "import networkx\n",
    "\n",
    "code_co_occurrence = networkx.Graph(directed=False, weighted=True)\n",
    "\n",
    "for code_list in codes:\n",
    "    for code in code_list:\n",
    "        if not code_co_occurrence.has_node(code):\n",
    "        code_co_occurrence.add_node(code)\n",
    "    for other_code in code_list:\n",
    "        if not code_co_occurrence.has_edge(code, other_code) and code != other_code:\n",
    "            code_co_occurrence.add_edge(code, other_code)\n",
    "            code_co_occurrence[code][other_code]['weight'] = 1\n",
    "        elif code_co_occurrence.has_edge(code, other_code):\n",
    "            code_co_occurrence[code][other_code]['weight'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPWAbw8abbnO"
   },
   "outputs": [],
   "source": [
    "code_co_occurrence.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gF7XHpMcXjc"
   },
   "outputs": [],
   "source": [
    "code_co_occurrence.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0y-0N1_xcYyq"
   },
   "outputs": [],
   "source": [
    "degrees = dict(code_co_occurrence.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRVuQ8pJcdgm"
   },
   "outputs": [],
   "source": [
    "np.mean(list(degrees.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdTHogPHcrq4"
   },
   "outputs": [],
   "source": [
    "top_5_nodes = dict(sorted(degrees.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "pd.DataFrame(top_5_nodes, index=[0]).T.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnqmBG4_czRp"
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "sns.histplot(list(degrees.values()), kde=True)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gt1PjPwLc4QG"
   },
   "outputs": [],
   "source": [
    "nodes_with_0_degree = [node for node in degrees if degrees[node] == 0]\n",
    "nodes_with_0_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WkUcbuUc_kr"
   },
   "outputs": [],
   "source": [
    "edge_weights = {}\n",
    "for edge in code_co_occurrence.edges:\n",
    "    edge_weights[edge] = code_co_occurrence[edge[0]][edge[1]]['weight']\n",
    "\n",
    "top_5_edges = dict(sorted(edge_weights.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "pd.DataFrame(top_5_edges, index=[0]).T.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9BHEyPWdHVy"
   },
   "outputs": [],
   "source": [
    "node_colors = {}\n",
    "for node in code_co_occurrence.nodes():\n",
    "    first_letter = node[0]\n",
    "    if first_letter not in node_colors:\n",
    "        node_colors[first_letter] = (plt.cm.get_cmap('hsv')(len(node_colors) / 26))\n",
    "\n",
    "node_color_list = [node_colors[node[0]] for node in code_co_occurrence.nodes()]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "pos = networkx.spring_layout(code_co_occurrence, seed=42, k=1, iterations=100)\n",
    "networkx.draw(code_co_occurrence, pos, with_labels=True, node_color=node_color_list, node_size=500, font_size=8, alpha=0.7, width=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvjkI2l6dmuK"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9Unt3hQdNOg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if len(device_name) > 0:\n",
    "    print(\"Found GPU at: {}\".format(device_name))\n",
    "else:\n",
    "    device_name = \"/device:CPU:0\"\n",
    "    print(\"No GPU, using {}.\".format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JNSRs8weaJQ"
   },
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = encoded_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2yJoOneepD5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=5401)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfgAduTge7h-"
   },
   "source": [
    "**Model 1 - Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMkc1iO0fBEk"
   },
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model1 = MultiOutputClassifier(DecisionTreeClassifier(class_weight='balanced', max_depth=2))\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {f1_score(y_train, model1.predict(X_train), average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model1.predict(X_val), average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bblk1uB9p9AG"
   },
   "source": [
    "**Model 2 - Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i0lL5GafNL0"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model2 = MultiOutputClassifier(LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {f1_score(y_train, model2.predict(X_train), average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model2.predict(X_val), average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TedXEc88qBZv"
   },
   "source": [
    "**Model 3 - Single Layer Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNqIpRmmp8he"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import F1Score\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with tf.device(device_name):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(1024, activation='relu'))\n",
    "    model3.add(Dense(1400, activation='sigmoid'))\n",
    "\n",
    "    metric = F1Score(average='micro')\n",
    "\n",
    "    model3.compile(optimizer='adam',loss='binary_crossentropy', metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model3.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cD2_f-xqmXE"
   },
   "outputs": [],
   "source": [
    "print(f\"Training score: {f1_score(y_train, model3.predict(X_train) > 0.5, average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model3.predict(X_val) > 0.5, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZvtCRYbqTh4"
   },
   "source": [
    "**Model 4 - Neural Network with Batch Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zhqK6mgqNeO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with tf.device(device_name):\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(1024, activation='relu'))\n",
    "    model4.add(BatchNormalization())\n",
    "    model4.add(Dense(1400, activation='sigmoid'))\n",
    "\n",
    "    metric = F1Score(average='micro')\n",
    "\n",
    "    model4.compile(optimizer='adam',loss='binary_crossentropy', metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model4.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hZJ7ZnwquV8"
   },
   "outputs": [],
   "source": [
    "print(f\"Training score: {f1_score(y_train, model4.predict(X_train) > 0.5, average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model4.predict(X_val) > 0.5, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0phaWYM1qc7X"
   },
   "source": [
    "**Model 5 - Neural Network with Min-Max Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dcVjjGAq1C8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with tf.device(device_name):\n",
    "    model5 = Sequential()\n",
    "    model5.add(Dense(1024, activation='relu'))\n",
    "    model5.add(BatchNormalization())\n",
    "    model5.add(Dense(1400, activation='sigmoid'))\n",
    "\n",
    "    metric = F1Score(average='micro')\n",
    "\n",
    "    model5.compile(optimizer='adam',loss='binary_crossentropy', metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model5.fit(\n",
    "    scaled_X_train, y_train,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQ7xNW9fquyJ"
   },
   "outputs": [],
   "source": [
    "print(f\"Training score: {f1_score(y_train, model5.predict(scaled_X_train) > 0.5, average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model5.predict(scaled_X_val) > 0.5, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COMJpFwdqhQF"
   },
   "source": [
    "**Model 6 - Neural Network with Additional Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vN-whPlKqlrj"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with tf.device(device_name):\n",
    "    model6 = Sequential()\n",
    "    model6.add(Dense(1024, activation='relu'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Dense(512, activation='relu'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Dense(1400, activation='sigmoid'))\n",
    "\n",
    "    metric = F1Score(average='micro')\n",
    "\n",
    "    model6.compile(optimizer='adam',loss='binary_crossentropy', metrics=[metric])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model6.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q68m4lcAqvRl"
   },
   "outputs": [],
   "source": [
    "print(f\"Training score: {f1_score(y_train, model6.predict(X_train) > 0.5, average='micro')}\")\n",
    "print(f\"Validation score: {f1_score(y_val, model6.predict(X_val) > 0.5, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1br9OxlrfL7"
   },
   "source": [
    "# Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u306mvT2rg33"
   },
   "outputs": [],
   "source": [
    "test_embeddings = np.load('/content/drive/MyDrive/da5401-2024-ml-challenge/test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JCmUAVytMtl"
   },
   "outputs": [],
   "source": [
    "test_predictions = model4.predict(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZHDV2SStPvU"
   },
   "outputs": [],
   "source": [
    "binary_test_predictions = (test_predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWCxVdZCtTfH"
   },
   "outputs": [],
   "source": [
    "codes_predicted = [\";\".join(sorted([all_codes[index] for index in range(len(prediction)) if prediction[index]==1])) for prediction in binary_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph66ubQFtV0R"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(codes_predicted, columns=['labels'], index=range(1,len(codes_predicted)+1)).reset_index().rename(columns={'index':'id'}).to_csv('be21b004_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
